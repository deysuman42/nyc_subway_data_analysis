{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subway Data Analysis\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The NYC public transportantion system - Metro Transit Authority - provides data for download via csv files. Part of the information available are data from the subway turnstiles, containing weekly logs for cumulative entries and exits by turnstile and by subway station during a provided timeframe.\n",
    "\n",
    "\n",
    "For this project, we will only use the information available at: http://web.mta.info/developers/turnstile.html.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this project\n",
    "\n",
    "For this project, you will apply the knowledge acquired in the first month of this course. We will practice basic data acquisition and data cleaning tasks to find out fundamental stuff about the data using what we learned in the Statistics course. \n",
    "\n",
    "The goal of this project is to explore the relationship between data from the NYC Subway turnstiles and the city weather. For this, besides data from the subway, we will also need data from the weather in NYC. \n",
    "\n",
    "Here are the main points that will be considered in this work:\n",
    "\n",
    "- Gathering data from the Internet\n",
    "- Using Statistics for Data Analysis\n",
    "- Data handling and simple graphics creation with `Pandas`\n",
    "\n",
    "*How to find help*: We suggest that you try the following channels, in the following order:\n",
    "\n",
    "| Type of Question\\Channels    \t| Google \t| Forum \t| Slack \t| Email \t|\n",
    "|-------------------------------\t|--------\t|-------\t|-------\t|-------\t|\n",
    "| Pandas and Python Programming \t| 1      \t| 2     \t| 3     \t|       \t|\n",
    "| Projects Requiriments         \t|        \t| 1     \t| 2     \t| 3     \t|\n",
    "| Projects Specific Parts       \t|        \t| 1     \t| 2     \t| 3     \t|\n",
    "\n",
    "Here is the address for each of these channels:\n",
    "\n",
    "- Forum: https://discussions.udacity.com/c/ndfdsi-project\n",
    "- Slack: [Big Data Foundations](https://goo.gl/4K7LWK)\n",
    "- Email: india@udacity.com\n",
    "\n",
    "**The student is expected to submit this report including:**\n",
    "\n",
    "- All TODO's completed, as they are crucial for the code to run accordingly\n",
    "- The ipynb file, exported as html\n",
    "\n",
    "To submit this project, go to the [classroom](https://coco.udacity.com/nanodegrees/nd100-inbig/locale/en-us/versions/1.0.0/parts/469348/modules/469702/lessons/469703/project), and submit your zipped `.ipynb` and html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminders\n",
    "\n",
    "Before we start, there are a few things you must have in mind while using iPython notebooks:\n",
    "\n",
    "- Remember you can see, in the left side of a code cell, when was the last time it ran, if there is a number inside the keys.\n",
    "- When starting a new session in the notebook, please make sure to run all cells up to the point where you last left it. Even if the output can still be viewed from the moment you ran your cells in the previews session, the kernel starts in a new state, so you will need to reload all data, etc. in a new session.\n",
    "- The previous point is useful to have in mind if your answers do not match what is expected from the quizzes in the classroom. Try reloading the data and running all processing steps, one by one, to make sure you're working with the same variables and data from each step of the quizz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 1 - Data Gathering\n",
    "\n",
    "### *Exercise 1.1*\n",
    "\n",
    "Let's do it!! Now it's your turn to gather data. Please write bellow a Python code to access the link http://web.mta.info/developers/turnstile.html and download all files from June 2017. The file must be named turnstile_100617.txt, where 10/06/17 is the file's date.\n",
    "\n",
    "Please see below a few commands that might help you:\n",
    "\n",
    "Use the **urllib** library to open and redeem a webpage. Use the command below, where **url** is the webpage path to the following file:\n",
    "\n",
    "```python\n",
    "u = urllib.urlopen(url)\n",
    "html = u.read()\n",
    "```\n",
    "\n",
    "Use the **BeautifulSoup** library to search for the link to the file you want to donwload in the page. Use the command below to create your *soup* object and search for all 'a' tags in the document:\n",
    " \n",
    " \n",
    "```python\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "links = soup.find_all('a')\n",
    "```\n",
    "\n",
    "A tip to only download the files from June is to check data in the name of the file. For instance, to donwload the 17/06/2017 file, please see if the link ends with *\"turnstile_170610.txt\"*. If you forget to do this, you will download all files from that page. In order to do this, you can use the following command:\n",
    "\n",
    "```python\n",
    "if '1706' in link.get('href'):\n",
    "```\n",
    "\n",
    "Our final tip is to use the command bellow to download the txt file:\n",
    "\n",
    "```python\n",
    "urllib.urlretrieve(link_do_arquivo, filename)\n",
    "```\n",
    "\n",
    "Please remember - you first have to load all packages and functions that will be used in your analysys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    import urllib\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    #your code here\n",
    "\n",
    "    #Open and Read the URL\n",
    "    u = urllib.urlopen('http://web.mta.info/developers/turnstile.html')\n",
    "    html = u.read()\n",
    "\n",
    "    #Parsing the URL to search for a specific pattern\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "    link = soup.find_all('a')\n",
    "\n",
    "\n",
    "    name = []\n",
    "    filenames = []\n",
    "\n",
    "    for i in link:\n",
    "        j = str(i)\n",
    "        if j.find('June') != -1 and j.find('2017') != -1:\n",
    "            name.append(j)\n",
    "\n",
    "    for k in range(0,len(name)):\n",
    "        url = 'http://web.mta.info/developers/' + name[k][9:49]\n",
    "        filename = name[k][29:39] + name[k][43:45] + name[k][41:43] + name[k][39:41] + '.txt'\n",
    "        filenames.append(filename)\n",
    "        urllib.urlretrieve(url, filename)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 1.2*\n",
    "\n",
    "Write down a function that takes the list of all names of the files you downloaded in Exercise 1.1 and compile them into one single file. There must be only one header line in the output file. \n",
    "\n",
    "For example, if file_1 has:\n",
    "line 1...\n",
    "line 2...\n",
    "\n",
    "and the other file, file_2, has:\n",
    "line 3...\n",
    "line 4...\n",
    "line 5...\n",
    "\n",
    "We must combine file_1 and file_2 into one master file, as follows:\n",
    "\n",
    "'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn'\n",
    "line 1...\n",
    "line 2...\n",
    "line 3...\n",
    "line 4...\n",
    "line 5...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "def create_master_turnstile_file(filenames, output_file):\n",
    "    \n",
    "    #open the file to write to master_file\n",
    "    with open(output_file, 'w') as master_file:\n",
    "        master_file.write('C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\\n')\n",
    "        for filename in filenames:\n",
    "            with open(filename, 'r') as data:\n",
    "                for line in data.readlines():\n",
    "                    #print line\n",
    "                    if line.find('C/A') != -1:\n",
    "                        continue\n",
    "                    elif line[4] != ',':\n",
    "                        y = line.find(',')\n",
    "                        match = re.search(r'\\d{2}:\\d{2}:\\d{2}', line).start()\n",
    "                        \n",
    "                        i = match - 11\n",
    "                        j = match - 1\n",
    "                        master_file.write(line[0:y] + line[y:y+15] + line[i+3:i+5] + '-' + line[i:i+2] + '-' + line[i+8:i+10] + line[j:] )\n",
    "                                          \n",
    "                    else:\n",
    "                        match = re.search(r'\\d{2}:\\d{2}:\\d{2}', line).start()\n",
    "                        i = match - 11\n",
    "                        j = match - 1\n",
    "                        master_file.write(line[0:19] +  line[i+3:i+5] + '-' + line[i:i+2] + '-' + line[i+8:i+10] + line[j:] )\n",
    "                                          \n",
    "\n",
    "\n",
    "           \n",
    "#def main():\n",
    "#create_master_turnstile_file(filenames, 'Master.txt')\n",
    "    \n",
    "\n",
    "#main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 1.3*\n",
    "\n",
    "For this exercise, you will write a function that reads the master_file created in the previous exercise and load it into a Pandas Dataframe. This function can be filtered, so that the Dataframe only has lines where column \"DESCn\" has the value \"Regular\".\n",
    "\n",
    "For example, if the Pandas Dataframe looks like this:\n",
    "    \n",
    "    ,C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    1,A002,R051,02-00-00,05-01-11,04:00:00,DOOR,3144335,1088159\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "    3,A002,R051,02-00-00,05-01-11,12:00:00,DOOR,3144424,1088231\n",
    "\n",
    "The Dataframe must look like the following, after filtering only the lines where column DESCn has the value REGULAR:\n",
    "\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def filter_by_regular(filename):\n",
    "    \n",
    "    #reading the csv file and converting into a dataframe\n",
    "    turnstile_data = pd.read_csv(filename) \n",
    "    # more of your code here\n",
    "    return turnstile_data[turnstile_data[\"DESCn\"] == \"REGULAR\"]\n",
    " \n",
    "#z = filter_by_regular('Master.txt')\n",
    "\n",
    "#def main():\n",
    "    #print(filter_by_regular('Output.txt'))\n",
    "#    print(z)\n",
    "    \n",
    "\n",
    "#main() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 1.4*\n",
    "\n",
    "\n",
    "The NYC Subway data has cumulative entry and exit data in each line. Let's assume you have a Dataframe called df, which contains only lines for one particular turnstile (unique SCP, C/A, and UNIT). The following function must change these cumulative entries for counting all entries since the last reading (entries from the last line of the Dataframe).\n",
    "\n",
    "More specifically, there are two things you should do:\n",
    "\n",
    "1 - Create a new column, called ENTRIESn_hourly\n",
    "2 - Insert in this column the difference between ENTRIESn in the current and the previous column. If the line has any NAN, fill it out/replace by 1.\n",
    "\n",
    "Tip: The funtions shift() and fillna() in Pandas might be usefull for this exercise.\n",
    "\n",
    "Below you will find and example of how your Dataframe should look by the end of this exercise:\n",
    "\n",
    "        C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn    EXITSn  ENTRIESn_hourly\n",
    "    0     A002  R051  02-00-00  05-01-11  00:00:00  REGULAR   3144312   1088151                1\n",
    "    1     A002  R051  02-00-00  05-01-11  04:00:00  REGULAR   3144335   1088159               23\n",
    "    2     A002  R051  02-00-00  05-01-11  08:00:00  REGULAR   3144353   1088177               18\n",
    "    3     A002  R051  02-00-00  05-01-11  12:00:00  REGULAR   3144424   1088231               71\n",
    "    4     A002  R051  02-00-00  05-01-11  16:00:00  REGULAR   3144594   1088275              170\n",
    "    5     A002  R051  02-00-00  05-01-11  20:00:00  REGULAR   3144808   1088317              214\n",
    "    6     A002  R051  02-00-00  05-02-11  00:00:00  REGULAR   3144895   1088328               87\n",
    "    7     A002  R051  02-00-00  05-02-11  04:00:00  REGULAR   3144905   1088331               10\n",
    "    8     A002  R051  02-00-00  05-02-11  08:00:00  REGULAR   3144941   1088420               36\n",
    "    9     A002  R051  02-00-00  05-02-11  12:00:00  REGULAR   3145094   1088753              153\n",
    "    10    A002  R051  02-00-00  05-02-11  16:00:00  REGULAR   3145337   1088823              243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn   EXITSn  \\\n",
      "0        A002  R051  02-00-00  17-06-17  00:00:00  REGULAR   6224816  2107317   \n",
      "1        A002  R051  02-00-00  17-06-17  04:00:00  REGULAR   6224850  2107322   \n",
      "2        A002  R051  02-00-00  17-06-17  08:00:00  REGULAR   6224885  2107352   \n",
      "3        A002  R051  02-00-00  17-06-17  12:00:00  REGULAR   6225005  2107452   \n",
      "4        A002  R051  02-00-00  17-06-17  16:00:00  REGULAR   6225248  2107513   \n",
      "5        A002  R051  02-00-00  17-06-17  20:00:00  REGULAR   6225548  2107565   \n",
      "6        A002  R051  02-00-00  18-06-17  00:00:00  REGULAR   6225716  2107586   \n",
      "7        A002  R051  02-00-00  18-06-17  04:00:00  REGULAR   6225741  2107590   \n",
      "8        A002  R051  02-00-00  18-06-17  08:00:00  REGULAR   6225762  2107607   \n",
      "9        A002  R051  02-00-00  18-06-17  12:00:00  REGULAR   6225879  2107676   \n",
      "10       A002  R051  02-00-00  18-06-17  16:00:00  REGULAR   6226063  2107714   \n",
      "11       A002  R051  02-00-00  18-06-17  20:00:00  REGULAR   6226295  2107755   \n",
      "12       A002  R051  02-00-00  19-06-17  00:00:00  REGULAR   6226407  2107778   \n",
      "13       A002  R051  02-00-00  19-06-17  04:00:00  REGULAR   6226413  2107779   \n",
      "14       A002  R051  02-00-00  19-06-17  08:00:00  REGULAR   6226460  2107870   \n",
      "15       A002  R051  02-00-00  19-06-17  12:00:00  REGULAR   6226625  2108117   \n",
      "16       A002  R051  02-00-00  19-06-17  16:00:00  REGULAR   6226906  2108190   \n",
      "17       A002  R051  02-00-00  19-06-17  20:00:00  REGULAR   6227611  2108288   \n",
      "18       A002  R051  02-00-00  20-06-17  00:00:00  REGULAR   6227770  2108316   \n",
      "19       A002  R051  02-00-00  20-06-17  04:00:00  REGULAR   6227785  2108321   \n",
      "20       A002  R051  02-00-00  20-06-17  08:00:00  REGULAR   6227837  2108448   \n",
      "21       A002  R051  02-00-00  20-06-17  12:00:00  REGULAR   6228001  2108732   \n",
      "22       A002  R051  02-00-00  20-06-17  16:00:00  REGULAR   6228295  2108798   \n",
      "23       A002  R051  02-00-00  20-06-17  20:00:00  REGULAR   6229118  2108869   \n",
      "24       A002  R051  02-00-00  21-06-17  00:00:00  REGULAR   6229332  2108905   \n",
      "25       A002  R051  02-00-00  21-06-17  04:00:00  REGULAR   6229347  2108906   \n",
      "26       A002  R051  02-00-00  21-06-17  08:00:00  REGULAR   6229394  2109010   \n",
      "27       A002  R051  02-00-00  21-06-17  12:00:00  REGULAR   6229553  2109269   \n",
      "28       A002  R051  02-00-00  21-06-17  16:00:00  REGULAR   6229829  2109341   \n",
      "29       A002  R051  02-00-00  21-06-17  20:00:00  REGULAR   6230582  2109401   \n",
      "...       ...   ...       ...       ...       ...      ...       ...      ...   \n",
      "788184  TRAM2  R469  00-05-01  29-05-17  01:00:00  REGULAR      5554      299   \n",
      "788185  TRAM2  R469  00-05-01  29-05-17  05:00:00  REGULAR      5554      299   \n",
      "788186  TRAM2  R469  00-05-01  29-05-17  09:00:00  REGULAR      5554      299   \n",
      "788187  TRAM2  R469  00-05-01  29-05-17  13:00:00  REGULAR      5554      299   \n",
      "788188  TRAM2  R469  00-05-01  29-05-17  17:00:00  REGULAR      5554      299   \n",
      "788189  TRAM2  R469  00-05-01  29-05-17  21:00:00  REGULAR      5554      299   \n",
      "788190  TRAM2  R469  00-05-01  30-05-17  01:00:00  REGULAR      5554      299   \n",
      "788191  TRAM2  R469  00-05-01  30-05-17  05:00:00  REGULAR      5554      299   \n",
      "788192  TRAM2  R469  00-05-01  30-05-17  09:00:00  REGULAR      5554      299   \n",
      "788193  TRAM2  R469  00-05-01  30-05-17  13:00:00  REGULAR      5554      299   \n",
      "788194  TRAM2  R469  00-05-01  30-05-17  17:00:00  REGULAR      5554      299   \n",
      "788195  TRAM2  R469  00-05-01  30-05-17  21:00:00  REGULAR      5554      299   \n",
      "788196  TRAM2  R469  00-05-01  31-05-17  01:00:00  REGULAR      5554      299   \n",
      "788197  TRAM2  R469  00-05-01  31-05-17  05:00:00  REGULAR      5554      299   \n",
      "788198  TRAM2  R469  00-05-01  31-05-17  09:00:00  REGULAR      5554      299   \n",
      "788199  TRAM2  R469  00-05-01  31-05-17  13:00:00  REGULAR      5554      299   \n",
      "788200  TRAM2  R469  00-05-01  31-05-17  17:00:00  REGULAR      5554      299   \n",
      "788201  TRAM2  R469  00-05-01  31-05-17  21:00:00  REGULAR      5554      299   \n",
      "788202  TRAM2  R469  00-05-01  01-06-17  01:00:00  REGULAR      5554      299   \n",
      "788203  TRAM2  R469  00-05-01  01-06-17  05:00:00  REGULAR      5554      299   \n",
      "788204  TRAM2  R469  00-05-01  01-06-17  09:00:00  REGULAR      5554      299   \n",
      "788205  TRAM2  R469  00-05-01  01-06-17  13:00:00  REGULAR      5554      299   \n",
      "788206  TRAM2  R469  00-05-01  01-06-17  17:00:00  REGULAR      5554      299   \n",
      "788207  TRAM2  R469  00-05-01  01-06-17  21:00:00  REGULAR      5554      299   \n",
      "788208  TRAM2  R469  00-05-01  02-06-17  01:00:00  REGULAR      5554      299   \n",
      "788209  TRAM2  R469  00-05-01  02-06-17  05:00:00  REGULAR      5554      299   \n",
      "788210  TRAM2  R469  00-05-01  02-06-17  09:00:00  REGULAR      5554      299   \n",
      "788211  TRAM2  R469  00-05-01  02-06-17  13:00:00  REGULAR      5554      299   \n",
      "788212  TRAM2  R469  00-05-01  02-06-17  17:00:00  REGULAR      5554      299   \n",
      "788213  TRAM2  R469  00-05-01  02-06-17  21:00:00  REGULAR      5554      299   \n",
      "\n",
      "        ENTRIESn_hourly  \n",
      "0                     1  \n",
      "1                    34  \n",
      "2                    35  \n",
      "3                   120  \n",
      "4                   243  \n",
      "5                   300  \n",
      "6                   168  \n",
      "7                    25  \n",
      "8                    21  \n",
      "9                   117  \n",
      "10                  184  \n",
      "11                  232  \n",
      "12                  112  \n",
      "13                    6  \n",
      "14                   47  \n",
      "15                  165  \n",
      "16                  281  \n",
      "17                  705  \n",
      "18                  159  \n",
      "19                   15  \n",
      "20                   52  \n",
      "21                  164  \n",
      "22                  294  \n",
      "23                  823  \n",
      "24                  214  \n",
      "25                   15  \n",
      "26                   47  \n",
      "27                  159  \n",
      "28                  276  \n",
      "29                  753  \n",
      "...                 ...  \n",
      "788184                0  \n",
      "788185                0  \n",
      "788186                0  \n",
      "788187                0  \n",
      "788188                0  \n",
      "788189                0  \n",
      "788190                0  \n",
      "788191                0  \n",
      "788192                0  \n",
      "788193                0  \n",
      "788194                0  \n",
      "788195                0  \n",
      "788196                0  \n",
      "788197                0  \n",
      "788198                0  \n",
      "788199                0  \n",
      "788200                0  \n",
      "788201                0  \n",
      "788202                0  \n",
      "788203                0  \n",
      "788204                0  \n",
      "788205                0  \n",
      "788206                0  \n",
      "788207                0  \n",
      "788208                0  \n",
      "788209                0  \n",
      "788210                0  \n",
      "788211                0  \n",
      "788212                0  \n",
      "788213                0  \n",
      "\n",
      "[785406 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "\n",
    "def get_hourly_entries(df):\n",
    "    \n",
    "    \n",
    "    df[\"ENTRIESn_hourly\"] = df[\"ENTRIESn\"].diff().fillna(1).astype(int)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    #your code here\n",
    "    \n",
    "#def main():\n",
    "    \n",
    "#    print(get_hourly_entries(z))\n",
    "    \n",
    "\n",
    "#main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 1.5*\n",
    "\n",
    "Do the same thing you did in the previous exercise, but taking into account the exits, column EXITSn.\n",
    "For this, you need to create a column called EXITSn_hourly and insert the difference between the column EXITSn in the current line vs he previous line. If there is any NaN, fill it out/replace by 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn   EXITSn  \\\n",
      "0        A002  R051  02-00-00  17-06-17  00:00:00  REGULAR   6224816  2107317   \n",
      "1        A002  R051  02-00-00  17-06-17  04:00:00  REGULAR   6224850  2107322   \n",
      "2        A002  R051  02-00-00  17-06-17  08:00:00  REGULAR   6224885  2107352   \n",
      "3        A002  R051  02-00-00  17-06-17  12:00:00  REGULAR   6225005  2107452   \n",
      "4        A002  R051  02-00-00  17-06-17  16:00:00  REGULAR   6225248  2107513   \n",
      "5        A002  R051  02-00-00  17-06-17  20:00:00  REGULAR   6225548  2107565   \n",
      "6        A002  R051  02-00-00  18-06-17  00:00:00  REGULAR   6225716  2107586   \n",
      "7        A002  R051  02-00-00  18-06-17  04:00:00  REGULAR   6225741  2107590   \n",
      "8        A002  R051  02-00-00  18-06-17  08:00:00  REGULAR   6225762  2107607   \n",
      "9        A002  R051  02-00-00  18-06-17  12:00:00  REGULAR   6225879  2107676   \n",
      "10       A002  R051  02-00-00  18-06-17  16:00:00  REGULAR   6226063  2107714   \n",
      "11       A002  R051  02-00-00  18-06-17  20:00:00  REGULAR   6226295  2107755   \n",
      "12       A002  R051  02-00-00  19-06-17  00:00:00  REGULAR   6226407  2107778   \n",
      "13       A002  R051  02-00-00  19-06-17  04:00:00  REGULAR   6226413  2107779   \n",
      "14       A002  R051  02-00-00  19-06-17  08:00:00  REGULAR   6226460  2107870   \n",
      "15       A002  R051  02-00-00  19-06-17  12:00:00  REGULAR   6226625  2108117   \n",
      "16       A002  R051  02-00-00  19-06-17  16:00:00  REGULAR   6226906  2108190   \n",
      "17       A002  R051  02-00-00  19-06-17  20:00:00  REGULAR   6227611  2108288   \n",
      "18       A002  R051  02-00-00  20-06-17  00:00:00  REGULAR   6227770  2108316   \n",
      "19       A002  R051  02-00-00  20-06-17  04:00:00  REGULAR   6227785  2108321   \n",
      "20       A002  R051  02-00-00  20-06-17  08:00:00  REGULAR   6227837  2108448   \n",
      "21       A002  R051  02-00-00  20-06-17  12:00:00  REGULAR   6228001  2108732   \n",
      "22       A002  R051  02-00-00  20-06-17  16:00:00  REGULAR   6228295  2108798   \n",
      "23       A002  R051  02-00-00  20-06-17  20:00:00  REGULAR   6229118  2108869   \n",
      "24       A002  R051  02-00-00  21-06-17  00:00:00  REGULAR   6229332  2108905   \n",
      "25       A002  R051  02-00-00  21-06-17  04:00:00  REGULAR   6229347  2108906   \n",
      "26       A002  R051  02-00-00  21-06-17  08:00:00  REGULAR   6229394  2109010   \n",
      "27       A002  R051  02-00-00  21-06-17  12:00:00  REGULAR   6229553  2109269   \n",
      "28       A002  R051  02-00-00  21-06-17  16:00:00  REGULAR   6229829  2109341   \n",
      "29       A002  R051  02-00-00  21-06-17  20:00:00  REGULAR   6230582  2109401   \n",
      "...       ...   ...       ...       ...       ...      ...       ...      ...   \n",
      "788184  TRAM2  R469  00-05-01  29-05-17  01:00:00  REGULAR      5554      299   \n",
      "788185  TRAM2  R469  00-05-01  29-05-17  05:00:00  REGULAR      5554      299   \n",
      "788186  TRAM2  R469  00-05-01  29-05-17  09:00:00  REGULAR      5554      299   \n",
      "788187  TRAM2  R469  00-05-01  29-05-17  13:00:00  REGULAR      5554      299   \n",
      "788188  TRAM2  R469  00-05-01  29-05-17  17:00:00  REGULAR      5554      299   \n",
      "788189  TRAM2  R469  00-05-01  29-05-17  21:00:00  REGULAR      5554      299   \n",
      "788190  TRAM2  R469  00-05-01  30-05-17  01:00:00  REGULAR      5554      299   \n",
      "788191  TRAM2  R469  00-05-01  30-05-17  05:00:00  REGULAR      5554      299   \n",
      "788192  TRAM2  R469  00-05-01  30-05-17  09:00:00  REGULAR      5554      299   \n",
      "788193  TRAM2  R469  00-05-01  30-05-17  13:00:00  REGULAR      5554      299   \n",
      "788194  TRAM2  R469  00-05-01  30-05-17  17:00:00  REGULAR      5554      299   \n",
      "788195  TRAM2  R469  00-05-01  30-05-17  21:00:00  REGULAR      5554      299   \n",
      "788196  TRAM2  R469  00-05-01  31-05-17  01:00:00  REGULAR      5554      299   \n",
      "788197  TRAM2  R469  00-05-01  31-05-17  05:00:00  REGULAR      5554      299   \n",
      "788198  TRAM2  R469  00-05-01  31-05-17  09:00:00  REGULAR      5554      299   \n",
      "788199  TRAM2  R469  00-05-01  31-05-17  13:00:00  REGULAR      5554      299   \n",
      "788200  TRAM2  R469  00-05-01  31-05-17  17:00:00  REGULAR      5554      299   \n",
      "788201  TRAM2  R469  00-05-01  31-05-17  21:00:00  REGULAR      5554      299   \n",
      "788202  TRAM2  R469  00-05-01  01-06-17  01:00:00  REGULAR      5554      299   \n",
      "788203  TRAM2  R469  00-05-01  01-06-17  05:00:00  REGULAR      5554      299   \n",
      "788204  TRAM2  R469  00-05-01  01-06-17  09:00:00  REGULAR      5554      299   \n",
      "788205  TRAM2  R469  00-05-01  01-06-17  13:00:00  REGULAR      5554      299   \n",
      "788206  TRAM2  R469  00-05-01  01-06-17  17:00:00  REGULAR      5554      299   \n",
      "788207  TRAM2  R469  00-05-01  01-06-17  21:00:00  REGULAR      5554      299   \n",
      "788208  TRAM2  R469  00-05-01  02-06-17  01:00:00  REGULAR      5554      299   \n",
      "788209  TRAM2  R469  00-05-01  02-06-17  05:00:00  REGULAR      5554      299   \n",
      "788210  TRAM2  R469  00-05-01  02-06-17  09:00:00  REGULAR      5554      299   \n",
      "788211  TRAM2  R469  00-05-01  02-06-17  13:00:00  REGULAR      5554      299   \n",
      "788212  TRAM2  R469  00-05-01  02-06-17  17:00:00  REGULAR      5554      299   \n",
      "788213  TRAM2  R469  00-05-01  02-06-17  21:00:00  REGULAR      5554      299   \n",
      "\n",
      "        ENTRIESn_hourly  EXITSn_hourly  \n",
      "0                     1              0  \n",
      "1                    34              5  \n",
      "2                    35             30  \n",
      "3                   120            100  \n",
      "4                   243             61  \n",
      "5                   300             52  \n",
      "6                   168             21  \n",
      "7                    25              4  \n",
      "8                    21             17  \n",
      "9                   117             69  \n",
      "10                  184             38  \n",
      "11                  232             41  \n",
      "12                  112             23  \n",
      "13                    6              1  \n",
      "14                   47             91  \n",
      "15                  165            247  \n",
      "16                  281             73  \n",
      "17                  705             98  \n",
      "18                  159             28  \n",
      "19                   15              5  \n",
      "20                   52            127  \n",
      "21                  164            284  \n",
      "22                  294             66  \n",
      "23                  823             71  \n",
      "24                  214             36  \n",
      "25                   15              1  \n",
      "26                   47            104  \n",
      "27                  159            259  \n",
      "28                  276             72  \n",
      "29                  753             60  \n",
      "...                 ...            ...  \n",
      "788184                0              0  \n",
      "788185                0              0  \n",
      "788186                0              0  \n",
      "788187                0              0  \n",
      "788188                0              0  \n",
      "788189                0              0  \n",
      "788190                0              0  \n",
      "788191                0              0  \n",
      "788192                0              0  \n",
      "788193                0              0  \n",
      "788194                0              0  \n",
      "788195                0              0  \n",
      "788196                0              0  \n",
      "788197                0              0  \n",
      "788198                0              0  \n",
      "788199                0              0  \n",
      "788200                0              0  \n",
      "788201                0              0  \n",
      "788202                0              0  \n",
      "788203                0              0  \n",
      "788204                0              0  \n",
      "788205                0              0  \n",
      "788206                0              0  \n",
      "788207                0              0  \n",
      "788208                0              0  \n",
      "788209                0              0  \n",
      "788210                0              0  \n",
      "788211                0              0  \n",
      "788212                0              0  \n",
      "788213                0              0  \n",
      "\n",
      "[785406 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "\n",
    "def get_hourly_entries(df):\n",
    "    \n",
    "    \n",
    "    df[\"EXITSn_hourly\"] = df[\"EXITSn\"].diff().fillna(0).astype(int)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    #your code here\n",
    "    \n",
    "#def main():\n",
    "    \n",
    "#    print(get_hourly_entries(z))\n",
    "    \n",
    "\n",
    "#main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 1.6*\n",
    "\n",
    "Given an entry variable that represents time, in the format:\n",
    "     \"00:00:00\" (hour: minutes: seconds)\n",
    "    \n",
    "Write a function to extract the hour part from the time in the entry variable\n",
    "And return it as an integer. For example:\n",
    "         \n",
    "         1) if hour is 00, your code must return 0\n",
    "         2) if hour is 01, your code must return 1\n",
    "         3) if hour is 21, your code must return 21\n",
    "        \n",
    "Please return te hour as an integer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dictionary defining each hour as key and its corresponding integer data as value\n",
    "dict_hour = {\"00\": 0, \n",
    "             \"01\": 1,\n",
    "             \"02\": 2,\n",
    "             \"03\": 3,\n",
    "             \"04\": 4,\n",
    "             \"05\": 5,\n",
    "             \"06\": 6,\n",
    "             \"07\": 7,\n",
    "             \"08\": 8,\n",
    "             \"09\": 9,\n",
    "             \"10\": 10,\n",
    "             \"11\": 11,\n",
    "             \"12\": 12,\n",
    "             \"13\": 13,\n",
    "             \"14\": 14,\n",
    "             \"15\": 15,\n",
    "             \"16\": 16,\n",
    "             \"17\": 17,\n",
    "             \"18\": 18,\n",
    "             \"19\": 19,\n",
    "             \"20\": 20,\n",
    "             \"21\": 21,\n",
    "             \"22\": 22,\n",
    "             \"23\": 23,\n",
    "             \"24\": 24}\n",
    "\n",
    "\n",
    "def time_to_hour(time):\n",
    "    if time[0:2] in dict_hour.keys():\n",
    "        hour = dict_hour.get(time[0:2])\n",
    "        return hour\n",
    "    \n",
    "\n",
    "    \n",
    "     # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Data Analysis\n",
    "\n",
    "### *Exercise 2.1*\n",
    "\n",
    "To understand the relationship between the Subway activity and the weather, please complete the data from the file already downloaded with the weather data.\n",
    "We provided you with the file containing NYC weather data and made it available with the Support Material. You can access it through the link: https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/turnstile_data_master_with_weather.csv\n",
    "\n",
    "Now that we have our data in a csv file, write Python code that reads this file and saves it into a Pandas Dataframe. \n",
    "\n",
    "Tip: \n",
    "\n",
    "Use the command below to read the file:\n",
    "\n",
    "```python\n",
    "pd.read_csv('output_list.txt', sep=\",\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        UNIT       DATEn     TIMEn  Hour    DESCn  ENTRIESn_hourly  \\\n",
      "0       R001  2011-05-01  01:00:00     1  REGULAR              0.0   \n",
      "1       R001  2011-05-01  05:00:00     5  REGULAR            217.0   \n",
      "2       R001  2011-05-01  09:00:00     9  REGULAR            890.0   \n",
      "3       R001  2011-05-01  13:00:00    13  REGULAR           2451.0   \n",
      "4       R001  2011-05-01  17:00:00    17  REGULAR           4400.0   \n",
      "5       R001  2011-05-01  21:00:00    21  REGULAR           3372.0   \n",
      "6       R002  2011-05-01  01:00:00     1  REGULAR              0.0   \n",
      "7       R002  2011-05-01  05:00:00     5  REGULAR             42.0   \n",
      "8       R002  2011-05-01  09:00:00     9  REGULAR             50.0   \n",
      "9       R002  2011-05-01  13:00:00    13  REGULAR            316.0   \n",
      "10      R002  2011-05-01  17:00:00    17  REGULAR            633.0   \n",
      "11      R002  2011-05-01  21:00:00    21  REGULAR            639.0   \n",
      "12      R003  2011-05-01  00:00:00     0  REGULAR              0.0   \n",
      "13      R003  2011-05-01  04:00:00     4  REGULAR              0.0   \n",
      "14      R003  2011-05-01  12:00:00    12  REGULAR              0.0   \n",
      "15      R003  2011-05-01  16:00:00    16  REGULAR              0.0   \n",
      "16      R003  2011-05-01  20:00:00    20  REGULAR              0.0   \n",
      "17      R004  2011-05-01  00:00:00     0  REGULAR              0.0   \n",
      "18      R004  2011-05-01  04:00:00     4  REGULAR              0.0   \n",
      "19      R004  2011-05-01  08:00:00     8  REGULAR              0.0   \n",
      "20      R004  2011-05-01  12:00:00    12  REGULAR              0.0   \n",
      "21      R004  2011-05-01  16:00:00    16  REGULAR              0.0   \n",
      "22      R004  2011-05-01  20:00:00    20  REGULAR              0.0   \n",
      "23      R005  2011-05-01  00:00:00     0  REGULAR              0.0   \n",
      "24      R005  2011-05-01  04:00:00     4  REGULAR              0.0   \n",
      "25      R005  2011-05-01  12:00:00    12  REGULAR              0.0   \n",
      "26      R005  2011-05-01  16:00:00    16  REGULAR              1.0   \n",
      "27      R005  2011-05-01  20:00:00    20  REGULAR              0.0   \n",
      "28      R006  2011-05-01  00:00:00     0  REGULAR              0.0   \n",
      "29      R006  2011-05-01  04:00:00     4  REGULAR              0.0   \n",
      "...      ...         ...       ...   ...      ...              ...   \n",
      "131921  R552  2011-05-30  17:55:25    17  REGULAR              6.0   \n",
      "131922  R552  2011-05-30  18:09:09    18  REGULAR            192.0   \n",
      "131923  R552  2011-05-30  18:15:11    18  REGULAR            350.0   \n",
      "131924  R552  2011-05-30  18:27:32    18  REGULAR             25.0   \n",
      "131925  R552  2011-05-30  18:46:54    18  REGULAR              0.0   \n",
      "131926  R552  2011-05-30  19:09:29    19  REGULAR             30.0   \n",
      "131927  R552  2011-05-30  19:11:30    19  REGULAR            208.0   \n",
      "131928  R552  2011-05-30  19:16:44    19  REGULAR            107.0   \n",
      "131929  R552  2011-05-30  19:23:45    19  REGULAR            139.0   \n",
      "131930  R552  2011-05-30  19:36:27    19  REGULAR            331.0   \n",
      "131931  R552  2011-05-30  19:38:47    19  REGULAR            275.0   \n",
      "131932  R552  2011-05-30  19:52:07    19  REGULAR            133.0   \n",
      "131933  R552  2011-05-30  20:10:01    20  REGULAR              7.0   \n",
      "131934  R552  2011-05-30  20:17:36    20  REGULAR            128.0   \n",
      "131935  R552  2011-05-30  20:23:06    20  REGULAR            142.0   \n",
      "131936  R552  2011-05-30  20:51:44    20  REGULAR              0.0   \n",
      "131937  R552  2011-05-30  20:58:04    20  REGULAR            248.0   \n",
      "131938  R552  2011-05-30  20:58:21    20  REGULAR             62.0   \n",
      "131939  R552  2011-05-30  21:14:49    21  REGULAR            116.0   \n",
      "131940  R552  2011-05-30  21:21:28    21  REGULAR             68.0   \n",
      "131941  R552  2011-05-30  22:07:25    22  REGULAR              7.0   \n",
      "131942  R552  2011-05-30  22:21:09    22  REGULAR             80.0   \n",
      "131943  R552  2011-05-30  22:27:11    22  REGULAR            195.0   \n",
      "131944  R552  2011-05-30  22:39:32    22  REGULAR             18.0   \n",
      "131945  R552  2011-05-30  22:58:54    22  REGULAR              0.0   \n",
      "131946  R552  2011-05-30  23:21:29    23  REGULAR             19.0   \n",
      "131947  R552  2011-05-30  23:23:30    23  REGULAR            158.0   \n",
      "131948  R552  2011-05-30  23:28:44    23  REGULAR             54.0   \n",
      "131949  R552  2011-05-30  23:35:45    23  REGULAR             59.0   \n",
      "131950  R552  2011-05-30  23:50:47    23  REGULAR            123.0   \n",
      "\n",
      "        EXITSn_hourly  maxpressurei  maxdewpti  mindewpti   ...     \\\n",
      "0                 0.0         30.31       42.0       35.0   ...      \n",
      "1               553.0         30.31       42.0       35.0   ...      \n",
      "2              1262.0         30.31       42.0       35.0   ...      \n",
      "3              3708.0         30.31       42.0       35.0   ...      \n",
      "4              2501.0         30.31       42.0       35.0   ...      \n",
      "5              2122.0         30.31       42.0       35.0   ...      \n",
      "6                 0.0         30.31       42.0       35.0   ...      \n",
      "7                66.0         30.31       42.0       35.0   ...      \n",
      "8               125.0         30.31       42.0       35.0   ...      \n",
      "9               716.0         30.31       42.0       35.0   ...      \n",
      "10              968.0         30.31       42.0       35.0   ...      \n",
      "11              566.0         30.31       42.0       35.0   ...      \n",
      "12                0.0         30.31       42.0       35.0   ...      \n",
      "13                0.0         30.31       42.0       35.0   ...      \n",
      "14                0.0         30.31       42.0       35.0   ...      \n",
      "15                0.0         30.31       42.0       35.0   ...      \n",
      "16                0.0         30.31       42.0       35.0   ...      \n",
      "17                0.0         30.31       42.0       35.0   ...      \n",
      "18                0.0         30.31       42.0       35.0   ...      \n",
      "19                0.0         30.31       42.0       35.0   ...      \n",
      "20                0.0         30.31       42.0       35.0   ...      \n",
      "21                0.0         30.31       42.0       35.0   ...      \n",
      "22                0.0         30.31       42.0       35.0   ...      \n",
      "23                0.0         30.31       42.0       35.0   ...      \n",
      "24                2.0         30.31       42.0       35.0   ...      \n",
      "25                2.0         30.31       42.0       35.0   ...      \n",
      "26                7.0         30.31       42.0       35.0   ...      \n",
      "27                0.0         30.31       42.0       35.0   ...      \n",
      "28                0.0         30.31       42.0       35.0   ...      \n",
      "29                1.0         30.31       42.0       35.0   ...      \n",
      "...               ...           ...        ...        ...   ...      \n",
      "131921            2.0         30.13       70.0       66.0   ...      \n",
      "131922           55.0         30.13       70.0       66.0   ...      \n",
      "131923           90.0         30.13       70.0       66.0   ...      \n",
      "131924            3.0         30.13       70.0       66.0   ...      \n",
      "131925            0.0         30.13       70.0       66.0   ...      \n",
      "131926            2.0         30.13       70.0       66.0   ...      \n",
      "131927          998.0         30.13       70.0       66.0   ...      \n",
      "131928          199.0         30.13       70.0       66.0   ...      \n",
      "131929           38.0         30.13       70.0       66.0   ...      \n",
      "131930          399.0         30.13       70.0       66.0   ...      \n",
      "131931           71.0         30.13       70.0       66.0   ...      \n",
      "131932           39.0         30.13       70.0       66.0   ...      \n",
      "131933          332.0         30.13       70.0       66.0   ...      \n",
      "131934          447.0         30.13       70.0       66.0   ...      \n",
      "131935          677.0         30.13       70.0       66.0   ...      \n",
      "131936            0.0         30.13       70.0       66.0   ...      \n",
      "131937          257.0         30.13       70.0       66.0   ...      \n",
      "131938           32.0         30.13       70.0       66.0   ...      \n",
      "131939          726.0         30.13       70.0       66.0   ...      \n",
      "131940          115.0         30.13       70.0       66.0   ...      \n",
      "131941            4.0         30.13       70.0       66.0   ...      \n",
      "131942           63.0         30.13       70.0       66.0   ...      \n",
      "131943          207.0         30.13       70.0       66.0   ...      \n",
      "131944            4.0         30.13       70.0       66.0   ...      \n",
      "131945            0.0         30.13       70.0       66.0   ...      \n",
      "131946           14.0         30.13       70.0       66.0   ...      \n",
      "131947         1022.0         30.13       70.0       66.0   ...      \n",
      "131948          275.0         30.13       70.0       66.0   ...      \n",
      "131949           46.0         30.13       70.0       66.0   ...      \n",
      "131950          108.0         30.13       70.0       66.0   ...      \n",
      "\n",
      "        meandewpti  meanpressurei  fog  rain  meanwindspdi  mintempi  \\\n",
      "0             39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "1             39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "2             39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "3             39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "4             39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "5             39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "6             39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "7             39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "8             39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "9             39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "10            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "11            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "12            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "13            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "14            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "15            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "16            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "17            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "18            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "19            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "20            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "21            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "22            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "23            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "24            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "25            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "26            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "27            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "28            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "29            39.0          30.27  0.0   0.0           5.0      50.0   \n",
      "...            ...            ...  ...   ...           ...       ...   \n",
      "131921        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131922        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131923        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131924        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131925        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131926        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131927        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131928        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131929        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131930        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131931        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131932        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131933        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131934        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131935        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131936        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131937        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131938        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131939        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131940        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131941        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131942        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131943        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131944        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131945        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131946        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131947        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131948        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131949        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "131950        68.0          30.08  0.0   1.0           5.0      70.0   \n",
      "\n",
      "        meantempi  maxtempi  precipi  thunder  \n",
      "0            60.0      69.0     0.00      0.0  \n",
      "1            60.0      69.0     0.00      0.0  \n",
      "2            60.0      69.0     0.00      0.0  \n",
      "3            60.0      69.0     0.00      0.0  \n",
      "4            60.0      69.0     0.00      0.0  \n",
      "5            60.0      69.0     0.00      0.0  \n",
      "6            60.0      69.0     0.00      0.0  \n",
      "7            60.0      69.0     0.00      0.0  \n",
      "8            60.0      69.0     0.00      0.0  \n",
      "9            60.0      69.0     0.00      0.0  \n",
      "10           60.0      69.0     0.00      0.0  \n",
      "11           60.0      69.0     0.00      0.0  \n",
      "12           60.0      69.0     0.00      0.0  \n",
      "13           60.0      69.0     0.00      0.0  \n",
      "14           60.0      69.0     0.00      0.0  \n",
      "15           60.0      69.0     0.00      0.0  \n",
      "16           60.0      69.0     0.00      0.0  \n",
      "17           60.0      69.0     0.00      0.0  \n",
      "18           60.0      69.0     0.00      0.0  \n",
      "19           60.0      69.0     0.00      0.0  \n",
      "20           60.0      69.0     0.00      0.0  \n",
      "21           60.0      69.0     0.00      0.0  \n",
      "22           60.0      69.0     0.00      0.0  \n",
      "23           60.0      69.0     0.00      0.0  \n",
      "24           60.0      69.0     0.00      0.0  \n",
      "25           60.0      69.0     0.00      0.0  \n",
      "26           60.0      69.0     0.00      0.0  \n",
      "27           60.0      69.0     0.00      0.0  \n",
      "28           60.0      69.0     0.00      0.0  \n",
      "29           60.0      69.0     0.00      0.0  \n",
      "...           ...       ...      ...      ...  \n",
      "131921       78.0      86.0     0.29      0.0  \n",
      "131922       78.0      86.0     0.29      0.0  \n",
      "131923       78.0      86.0     0.29      0.0  \n",
      "131924       78.0      86.0     0.29      0.0  \n",
      "131925       78.0      86.0     0.29      0.0  \n",
      "131926       78.0      86.0     0.29      0.0  \n",
      "131927       78.0      86.0     0.29      0.0  \n",
      "131928       78.0      86.0     0.29      0.0  \n",
      "131929       78.0      86.0     0.29      0.0  \n",
      "131930       78.0      86.0     0.29      0.0  \n",
      "131931       78.0      86.0     0.29      0.0  \n",
      "131932       78.0      86.0     0.29      0.0  \n",
      "131933       78.0      86.0     0.29      0.0  \n",
      "131934       78.0      86.0     0.29      0.0  \n",
      "131935       78.0      86.0     0.29      0.0  \n",
      "131936       78.0      86.0     0.29      0.0  \n",
      "131937       78.0      86.0     0.29      0.0  \n",
      "131938       78.0      86.0     0.29      0.0  \n",
      "131939       78.0      86.0     0.29      0.0  \n",
      "131940       78.0      86.0     0.29      0.0  \n",
      "131941       78.0      86.0     0.29      0.0  \n",
      "131942       78.0      86.0     0.29      0.0  \n",
      "131943       78.0      86.0     0.29      0.0  \n",
      "131944       78.0      86.0     0.29      0.0  \n",
      "131945       78.0      86.0     0.29      0.0  \n",
      "131946       78.0      86.0     0.29      0.0  \n",
      "131947       78.0      86.0     0.29      0.0  \n",
      "131948       78.0      86.0     0.29      0.0  \n",
      "131949       78.0      86.0     0.29      0.0  \n",
      "131950       78.0      86.0     0.29      0.0  \n",
      "\n",
      "[131951 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "filename = \"turnstile_data_master_with_weather.csv\"\n",
    "\n",
    "#Read and convert the file into a dataframe\n",
    "weather_df = pd.read_csv(filename, sep = \",\" , index_col=0)\n",
    "\n",
    "#print weather_df\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 2.2*\n",
    "\n",
    "Now, create a function that calculates the number of rainy days. For this, return the count of the number of days where the column *\"rain\"* is equal to 1.\n",
    "\n",
    "Tip: You might think that interpreting numbers as integers or floats might not\n",
    "     work at first. To handle this issue, it might be useful to convert\n",
    "     these numbers into integers. You can do this by writting cast (column as integer).\n",
    "     So, for example, if we want to launch the column maxtempi as an integer, we have to\n",
    "     write something like cast (maxtempi as integer) = 76, instead of just\n",
    "     where maxtempi = 76."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def num_rainy_days(df):\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for i in weather_df['rain'].astype(int):\n",
    "        \n",
    "        if i == 1:\n",
    "            \n",
    "            count += 1\n",
    "        else:\n",
    "            \n",
    "            continue\n",
    "    return count \n",
    "\n",
    "    \n",
    "#count_rain = num_rainy_days(weather_df)\n",
    "\n",
    "    #your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 2.3*\n",
    "\n",
    "Calculate if the day was cloudy or not (0 or 1) and the maximum temperature for fog (i.e. the maximum temperature \n",
    "     for cloudy days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def max_temp_aggregate_by_fog(df):\n",
    "    \n",
    "    \n",
    "    group_by_fog = df.groupby(['fog'], as_index=False)['maxtempi'].max()\n",
    "    \n",
    "    filter_data = group_by_fog[group_by_fog['fog'].astype(int) == 1]\n",
    "    \n",
    "    temp_data = filter_data['maxtempi']\n",
    "    \n",
    "    max_temp = temp_data.to_string(index=False)\n",
    "    \n",
    "    return max_temp\n",
    "    #your code here \n",
    "    \n",
    "#max_temp_fog = max_temp_aggregate_by_fog(weather_df)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 2.4\n",
    "\n",
    "Now, calculate the mean for 'meantempi' for the days that are Saturdays or Sundays (weekend):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.100666854\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def avg_weekend_temperature(filename):\n",
    "    \n",
    "    #Reading the CSV file into a dataframne to perform the operation\n",
    "    \n",
    "    df_file = pd.read_csv(filename, sep = \",\" , index_col=0)\n",
    "  \n",
    "    df_file['DATEn'] = pd.to_datetime(df_file['DATEn'])\n",
    "    \n",
    "    df_file['day_of_week'] = df_file['DATEn'].dt.weekday_name\n",
    "    \n",
    "    k = df_file[['DATEn' , 'meantempi' , 'day_of_week']]\n",
    "    \n",
    "    z = k[(k['day_of_week']=='Saturday') | (k['day_of_week']=='Sunday')]\n",
    "    \n",
    "    mean_temp = z['meantempi'].astype(float).mean()\n",
    "    \n",
    "    return mean_temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 2.5\n",
    "\n",
    "Calculate the mean of the minimum temperature 'mintempi' for the days when the minimum temperature was greater that 55 degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.2699012987\n"
     ]
    }
   ],
   "source": [
    "def avg_min_temperature(filename):\n",
    "    \n",
    "    avg_df = pd.read_csv(filename, sep = \",\" , index_col=0)\n",
    "\n",
    "    mean_min_temp = avg_df[avg_df['mintempi'].astype(int) > 55]\n",
    "    \n",
    "    avg_min_temp_rainy = mean_min_temp['mintempi'].astype(float).mean()\n",
    "     \n",
    "    \n",
    "    return avg_min_temp_rainy\n",
    "\n",
    "#avg_min_temp = avg_min_temperature(weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 2.6\n",
    "\n",
    "Before you make any analysis, it might be useful to look at the data we want to analyse. More specifically, we will evaluate the entries by hour in our data from the NYC Subway to determine the data distribution. This data is stored in the column ['ENTRIESn_hourly'].\n",
    "    \n",
    "Draw two histogramns in the same axis, to show the entries when it's raining vs when it's not. \n",
    "Below, you will find an example of how to draw histogramns with Pandas and Matplotlib:\n",
    "     \n",
    "```python\n",
    "Turnstile_weather ['column_to_graph']. Hist ()\n",
    "```   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXBzMzKzg4mBmZgUXBzMzK7g4mJlZ4f8DyCF4NyJ7g2cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf77d518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'C:\\Users\\SUMAN DEY\\Anaconda2\\lib\\site-packages\\matplotlib\\pyplot.pyc'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def entries_histogram(turnstile_weather):\n",
    "    \n",
    "    \n",
    "    \n",
    "    #plt.show()\n",
    "    \n",
    "    temp_data = turnstile_weather[['rain','ENTRIESn_hourly']]\n",
    "    \n",
    "    rain_data = temp_data[temp_data[\"rain\"] == 1.0]\n",
    "    no_rain_data = temp_data[temp_data[\"rain\"] == 0.0]\n",
    "    \n",
    "    #temp_data.hist('rain',weights=temp_data['ENTRIESn_hourly'] )\n",
    "    #temp_data['ENTRIESn_hourly'].plot.hist(stacked=True, alpha=0.5)\n",
    "    rain_data['ENTRIESn_hourly'].hist(alpha=0.5)\n",
    "    no_rain_data['ENTRIESn_hourly'].hist(alpha=0.5)\n",
    "    \n",
    "    plt.show()\n",
    "  \n",
    "\n",
    "   \n",
    "    return plt\n",
    "\n",
    "#entries_histogram(weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 2.7\n",
    "\n",
    "The data you just plotted is in what kind of distribution? Is there a difference in distribution between rainy and non-rainy days?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Answer **: The data plotted shows positively skewed distribution. It shows the difference in distrbution between rainy and non-rainy days. The Hourly Entries are more when it is not raining compared to when it is raining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 2.8\n",
    "\n",
    "Build a function that returns:\n",
    "\n",
    "1. The mean of entries when it's raining\n",
    "2. The mean of entries when it's not raining\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1105.4463767458733, 1090.278780151855)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas\n",
    "\n",
    "def means(turnstile_weather):\n",
    "    \n",
    "    temp_data = turnstile_weather[['rain','ENTRIESn_hourly']]\n",
    "    \n",
    "    rain_entry = temp_data[temp_data['rain'].astype(int) == 1]\n",
    "    no_rain_entry = temp_data[temp_data['rain'].astype(int) == 0]\n",
    "    \n",
    "    with_rain_mean = rain_entry['ENTRIESn_hourly'].astype(float).mean()\n",
    "    without_rain_mean = no_rain_entry['ENTRIESn_hourly'].astype(float).mean()\n",
    "    ### YOUR CODE HERE ###\n",
    "    \n",
    "    \n",
    "    return with_rain_mean, without_rain_mean, #p # leave this line for the grader\n",
    "\n",
    "#mean = means(weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer to the following questions according to your functions' exits:\n",
    "\n",
    "1. What is the mean of entries when it's raining?\n",
    "2. What is the mean of entries when it's not raining?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Answer **: 1. 1105.4463767458733\n",
    "              2. 1090.278780151855"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Map Reduce\n",
    "\n",
    "### *Exercise 3.1*\n",
    "\n",
    "The entry for this exercise is the same file from the previous session (Exercise 2). You can download the file from this link:\n",
    "\n",
    " https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/turnstile_data_master_with_weather.csv\n",
    "\n",
    "Now, we will create a mapper. For each entry line, the mapper exit must PRINT (not return) UNIT as a key, and the number of ENTRIESn_hourly as the value. Separate the key and the value with a tab. For example: 'R002 \\ t105105.0'\n",
    "\n",
    "Export your mapper into a file named mapper_result.txt and send it with your submission. The code for exporting your mapper is already written in the code bellow.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "\n",
    "def mapper():\n",
    "    \n",
    "    \n",
    "    reader = csv.reader(sys.stdin, delimiter = ',')\n",
    "    \n",
    "\n",
    "    for line in reader:\n",
    "        \n",
    "            \n",
    "        if len(line) == 22:\n",
    "                \n",
    "            lunit = line[1]\n",
    "            le_entry = line[6]\n",
    "                \n",
    "            if lunit == 'UNIT':\n",
    "                continue\n",
    "            else:\n",
    "                print \"{0}\\t{1}\".format(lunit, le_entry)\n",
    "            \n",
    "           \n",
    "         \n",
    "        # your code here\n",
    "\n",
    "sys.stdin = open('turnstile_data_master_with_weather.csv')\n",
    "sys.stdout = open('mapper_result.txt', 'w')\n",
    "mapper()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 3.2*\n",
    "\n",
    "Now, create the reducer. Given the mapper result from the previous exercise, the reducer must print (not return) one line per UNIT, with the total number of ENTRIESn_hourly during May (which is our data duration), separated by a tab. An example of exit line from the reducer may look like this: 'R001 \\ t500625.0'\n",
    "\n",
    "You can assume that the entry for the reducer is ordered in a way that all lines corresponding to a particular unit are grouped. However, the reducer exit will have repetition, as there are stores that appear in different files' locations.\n",
    "\n",
    "Export your reducer into a file named reducer_result.txt and send it with your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def reducer():\n",
    "    \n",
    "    entryTotal = 0.0\n",
    "    oldKey = None\n",
    "    for line in sys.stdin:\n",
    "        data_mapped = line.strip().split(\"\\t\")\n",
    "        if len(data_mapped) != 2:\n",
    "            \n",
    "        # Something has gone wrong. Skip this line.\n",
    "            continue\n",
    "\n",
    "        thisKey, thisEntry = data_mapped\n",
    "\n",
    "        if oldKey and oldKey != thisKey:\n",
    "            print oldKey, \"\\t\", entryTotal\n",
    "            oldKey = thisKey;\n",
    "            entryTotal = 0.0\n",
    "\n",
    "        oldKey = thisKey\n",
    "        entryTotal += float(thisEntry)\n",
    "\n",
    "    if oldKey != None:\n",
    "        print oldKey, \"\\t\", entryTotal\n",
    "          # your code here\n",
    "\n",
    "sys.stdin = open('mapper_result.txt', 'r') \n",
    "sys.stdout = open('reducer_result.txt', 'w')       \n",
    "reducer()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
